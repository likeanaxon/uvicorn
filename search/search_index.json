{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The lightning-fast ASGI server. Introduction \u00b6 Uvicorn is a lightning-fast ASGI server implementation, using uvloop and httptools . Until recently Python has lacked a minimal low-level server/application interface for asyncio frameworks. The ASGI specification fills this gap, and means we're now able to start building a common set of tooling usable across all asyncio frameworks. ASGI should help enable an ecosystem of Python web frameworks that are highly competitive against Node and Go in terms of achieving high throughput in IO-bound contexts. It also provides support for HTTP/2 and WebSockets, which cannot be handled by WSGI. Uvicorn currently supports HTTP/1.1 and WebSockets. Support for HTTP/2 is planned. Quickstart \u00b6 Install using pip : $ pip install uvicorn This will install uvicorn with minimal (pure Python) dependencies. $ pip install uvicorn [ standard ] This will install uvicorn with \"Cython-based\" dependencies (where possible) and other \"optional extras\". In this context, \"Cython-based\" means the following: the event loop uvloop will be installed and used if possible. the http protocol will be handled by httptools if possible. Moreover, \"optional extras\" means that: the websocket protocol will be handled by websockets (should you want to use wsproto you'd need to install it manually) if possible. the --reloader flag in development mode will use watchgod . windows users will have colorama installed for the colored logs. python-dotenv will be installed should you want to use the --env-file option. PyYAML will be installed to allow you to provide a .yaml file to --log-config , if desired. Create an application, in example.py : async def app ( scope , receive , send ): assert scope [ 'type' ] == 'http' await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ], }) await send ({ 'type' : 'http.response.body' , 'body' : b 'Hello, world!' , }) Run the server: $ uvicorn example:app Usage \u00b6 The uvicorn command line tool is the easiest way to run your application... Command line options \u00b6 Usage: uvicorn [OPTIONS] APP Options: --host TEXT Bind socket to this host. [default: 127.0.0.1] --port INTEGER Bind socket to this port. [default: 8000] --uds TEXT Bind to a UNIX domain socket. --fd INTEGER Bind to socket from this file descriptor. --reload Enable auto-reload. --reload-dir TEXT Set reload directories explicitly, instead of using the current working directory. --workers INTEGER Number of worker processes. Defaults to the $WEB_CONCURRENCY environment variable if available. Not valid with --reload. --loop [auto|asyncio|uvloop] Event loop implementation. [default: auto] --http [auto|h11|httptools] HTTP protocol implementation. [default: auto] --ws [auto|none|websockets|wsproto] WebSocket protocol implementation. [default: auto] --lifespan [auto|on|off] Lifespan implementation. [default: auto] --interface [auto|asgi3|asgi2|wsgi] Select ASGI3, ASGI2, or WSGI as the application interface. [default: auto] --env-file PATH Environment configuration file. --log-config PATH Logging configuration file. Supported formats (.ini, .json, .yaml) --log-level [critical|error|warning|info|debug|trace] Log level. [default: info] --access-log / --no-access-log Enable/Disable access log. --use-colors / --no-use-colors Enable/Disable colorized logging. --proxy-headers / --no-proxy-headers Enable/Disable X-Forwarded-Proto, X-Forwarded-For, X-Forwarded-Port to populate remote address info. --forwarded-allow-ips TEXT Comma separated list of IPs to trust with proxy headers. Defaults to the $FORWARDED_ALLOW_IPS environment variable if available, or '127.0.0.1'. --root-path TEXT Set the ASGI 'root_path' for applications submounted below a given URL path. --limit-concurrency INTEGER Maximum number of concurrent connections or tasks to allow, before issuing HTTP 503 responses. --backlog INTEGER Maximum number of connections to hold in backlog --limit-max-requests INTEGER Maximum number of requests to service before terminating the process. --timeout-keep-alive INTEGER Close Keep-Alive connections if no new data is received within this timeout. [default: 5] --ssl-keyfile TEXT SSL key file --ssl-certfile TEXT SSL certificate file --ssl-keyfile-password TEXT SSL key file password --ssl-version INTEGER SSL version to use (see stdlib ssl module's) [default: 2] --ssl-cert-reqs INTEGER Whether client certificate is required (see stdlib ssl module's) [default: 0] --ssl-ca-certs TEXT CA certificates file --ssl-ciphers TEXT Ciphers to use (see stdlib ssl module's) [default: TLSv1] --header TEXT Specify custom default HTTP response headers as a Name:Value pair --factory Treat APP as an application factory, i.e. a () -> <ASGI app> function. [default: False] --help Show this message and exit. For more information, see the settings documentation . Running programmatically \u00b6 To run uvicorn directly from your application... example.py : import uvicorn async def app ( scope , receive , send ): ... if __name__ == \"__main__\" : uvicorn . run ( \"example:app\" , host = \"127.0.0.1\" , port = 5000 , log_level = \"info\" ) Running with Gunicorn \u00b6 Gunicorn is a mature, fully featured server and process manager. Uvicorn includes a Gunicorn worker class allowing you to run ASGI applications, with all of Uvicorn's performance benefits, while also giving you Gunicorn's fully-featured process management. This allows you to increase or decrease the number of worker processes on the fly, restart worker processes gracefully, or perform server upgrades without downtime. For production deployments we recommend using gunicorn with the uvicorn worker class. gunicorn example:app -w 4 -k uvicorn.workers.UvicornWorker For a PyPy compatible configuration use uvicorn.workers.UvicornH11Worker . For more information, see the deployment documentation . Application factories \u00b6 The --factory flag allows loading the application from a factory function, rather than an application instance directly. The factory will be called with no arguments and should return an ASGI application. example.py : def create_app (): app = ... return app $ uvicorn --factory example:create_app The ASGI interface \u00b6 Uvicorn uses the ASGI specification for interacting with an application. The application should expose an async callable which takes three arguments: scope - A dictionary containing information about the incoming connection. receive - A channel on which to receive incoming messages from the server. send - A channel on which to send outgoing messages to the server. Two common patterns you might use are either function-based applications: async def app ( scope , receive , send ): assert scope [ 'type' ] == 'http' ... Or instance-based applications: class App : async def __call__ ( self , scope , receive , send ): assert scope [ 'type' ] == 'http' ... app = App () It's good practice for applications to raise an exception on scope types that they do not handle. The content of the scope argument, and the messages expected by receive and send depend on the protocol being used. The format for HTTP messages is described in the ASGI HTTP Message format . HTTP Scope \u00b6 An incoming HTTP request might have a connection scope like this: { 'type' : 'http.request' , 'scheme' : 'http' , 'root_path' : '' , 'server' : ( '127.0.0.1' , 8000 ), 'http_version' : '1.1' , 'method' : 'GET' , 'path' : '/' , 'headers' : [ [ b 'host' , b '127.0.0.1:8000' ], [ b 'user-agent' , b 'curl/7.51.0' ], [ b 'accept' , b '*/*' ] ] } HTTP Messages \u00b6 The instance coroutine communicates back to the server by sending messages to the send coroutine. await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ] }) await send ({ 'type' : 'http.response.body' , 'body' : b 'Hello, world!' , }) Requests & responses \u00b6 Here's an example that displays the method and path used in the incoming request: async def app ( scope , receive , send ): \"\"\" Echo the method and path back in an HTTP response. \"\"\" assert scope [ 'type' ] == 'http' body = f 'Received { scope [ \"method\" ] } request to { scope [ \"path\" ] } ' await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ] }) await send ({ 'type' : 'http.response.body' , 'body' : body . encode ( 'utf-8' ), }) Reading the request body \u00b6 You can stream the request body without blocking the asyncio task pool, by fetching messages from the receive coroutine. async def read_body ( receive ): \"\"\" Read and return the entire body from an incoming ASGI message. \"\"\" body = b '' more_body = True while more_body : message = await receive () body += message . get ( 'body' , b '' ) more_body = message . get ( 'more_body' , False ) return body async def app ( scope , receive , send ): \"\"\" Echo the request body back in an HTTP response. \"\"\" body = await read_body ( receive ) await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ] }) await send ({ 'type' : 'http.response.body' , 'body' : body , }) Streaming responses \u00b6 You can stream responses by sending multiple http.response.body messages to the send coroutine. import asyncio async def app ( scope , receive , send ): \"\"\" Send a slowly streaming HTTP response back to the client. \"\"\" await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ] }) for chunk in [ b 'Hello' , b ', ' , b 'world!' ]: await send ({ 'type' : 'http.response.body' , 'body' : chunk , 'more_body' : True }) await asyncio . sleep ( 1 ) await send ({ 'type' : 'http.response.body' , 'body' : b '' , }) Alternative ASGI servers \u00b6 Daphne \u00b6 The first ASGI server implementation, originally developed to power Django Channels, is the Daphne webserver . It is run widely in production, and supports HTTP/1.1, HTTP/2, and WebSockets. Any of the example applications given here can equally well be run using daphne instead. $ pip install daphne $ daphne app:App Hypercorn \u00b6 Hypercorn was initially part of the Quart web framework, before being separated out into a standalone ASGI server. Hypercorn supports HTTP/1.1, HTTP/2, and WebSockets. $ pip install hypercorn $ hypercorn app:App ASGI frameworks \u00b6 You can use Uvicorn, Daphne, or Hypercorn to run any ASGI framework. For small services you can also write ASGI applications directly. Starlette \u00b6 Starlette is a lightweight ASGI framework/toolkit. It is ideal for building high performance asyncio services, and supports both HTTP and WebSockets. Django Channels \u00b6 The ASGI specification was originally designed for use with Django Channels . Channels is a little different to other ASGI frameworks in that it provides an asynchronous frontend onto a threaded-framework backend. It allows Django to support WebSockets, background tasks, and long-running connections, with application code still running in a standard threaded context. Quart \u00b6 Quart is a Flask-like ASGI web framework. FastAPI \u00b6 FastAPI is an API framework based on Starlette and Pydantic , heavily inspired by previous server versions of APIStar . You write your API function parameters with Python 3.6+ type declarations and get automatic data conversion, data validation, OpenAPI schemas (with JSON Schemas) and interactive API documentation UIs.","title":"Introduction"},{"location":"#introduction","text":"Uvicorn is a lightning-fast ASGI server implementation, using uvloop and httptools . Until recently Python has lacked a minimal low-level server/application interface for asyncio frameworks. The ASGI specification fills this gap, and means we're now able to start building a common set of tooling usable across all asyncio frameworks. ASGI should help enable an ecosystem of Python web frameworks that are highly competitive against Node and Go in terms of achieving high throughput in IO-bound contexts. It also provides support for HTTP/2 and WebSockets, which cannot be handled by WSGI. Uvicorn currently supports HTTP/1.1 and WebSockets. Support for HTTP/2 is planned.","title":"Introduction"},{"location":"#quickstart","text":"Install using pip : $ pip install uvicorn This will install uvicorn with minimal (pure Python) dependencies. $ pip install uvicorn [ standard ] This will install uvicorn with \"Cython-based\" dependencies (where possible) and other \"optional extras\". In this context, \"Cython-based\" means the following: the event loop uvloop will be installed and used if possible. the http protocol will be handled by httptools if possible. Moreover, \"optional extras\" means that: the websocket protocol will be handled by websockets (should you want to use wsproto you'd need to install it manually) if possible. the --reloader flag in development mode will use watchgod . windows users will have colorama installed for the colored logs. python-dotenv will be installed should you want to use the --env-file option. PyYAML will be installed to allow you to provide a .yaml file to --log-config , if desired. Create an application, in example.py : async def app ( scope , receive , send ): assert scope [ 'type' ] == 'http' await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ], }) await send ({ 'type' : 'http.response.body' , 'body' : b 'Hello, world!' , }) Run the server: $ uvicorn example:app","title":"Quickstart"},{"location":"#usage","text":"The uvicorn command line tool is the easiest way to run your application...","title":"Usage"},{"location":"#command-line-options","text":"Usage: uvicorn [OPTIONS] APP Options: --host TEXT Bind socket to this host. [default: 127.0.0.1] --port INTEGER Bind socket to this port. [default: 8000] --uds TEXT Bind to a UNIX domain socket. --fd INTEGER Bind to socket from this file descriptor. --reload Enable auto-reload. --reload-dir TEXT Set reload directories explicitly, instead of using the current working directory. --workers INTEGER Number of worker processes. Defaults to the $WEB_CONCURRENCY environment variable if available. Not valid with --reload. --loop [auto|asyncio|uvloop] Event loop implementation. [default: auto] --http [auto|h11|httptools] HTTP protocol implementation. [default: auto] --ws [auto|none|websockets|wsproto] WebSocket protocol implementation. [default: auto] --lifespan [auto|on|off] Lifespan implementation. [default: auto] --interface [auto|asgi3|asgi2|wsgi] Select ASGI3, ASGI2, or WSGI as the application interface. [default: auto] --env-file PATH Environment configuration file. --log-config PATH Logging configuration file. Supported formats (.ini, .json, .yaml) --log-level [critical|error|warning|info|debug|trace] Log level. [default: info] --access-log / --no-access-log Enable/Disable access log. --use-colors / --no-use-colors Enable/Disable colorized logging. --proxy-headers / --no-proxy-headers Enable/Disable X-Forwarded-Proto, X-Forwarded-For, X-Forwarded-Port to populate remote address info. --forwarded-allow-ips TEXT Comma separated list of IPs to trust with proxy headers. Defaults to the $FORWARDED_ALLOW_IPS environment variable if available, or '127.0.0.1'. --root-path TEXT Set the ASGI 'root_path' for applications submounted below a given URL path. --limit-concurrency INTEGER Maximum number of concurrent connections or tasks to allow, before issuing HTTP 503 responses. --backlog INTEGER Maximum number of connections to hold in backlog --limit-max-requests INTEGER Maximum number of requests to service before terminating the process. --timeout-keep-alive INTEGER Close Keep-Alive connections if no new data is received within this timeout. [default: 5] --ssl-keyfile TEXT SSL key file --ssl-certfile TEXT SSL certificate file --ssl-keyfile-password TEXT SSL key file password --ssl-version INTEGER SSL version to use (see stdlib ssl module's) [default: 2] --ssl-cert-reqs INTEGER Whether client certificate is required (see stdlib ssl module's) [default: 0] --ssl-ca-certs TEXT CA certificates file --ssl-ciphers TEXT Ciphers to use (see stdlib ssl module's) [default: TLSv1] --header TEXT Specify custom default HTTP response headers as a Name:Value pair --factory Treat APP as an application factory, i.e. a () -> <ASGI app> function. [default: False] --help Show this message and exit. For more information, see the settings documentation .","title":"Command line options"},{"location":"#running-programmatically","text":"To run uvicorn directly from your application... example.py : import uvicorn async def app ( scope , receive , send ): ... if __name__ == \"__main__\" : uvicorn . run ( \"example:app\" , host = \"127.0.0.1\" , port = 5000 , log_level = \"info\" )","title":"Running programmatically"},{"location":"#running-with-gunicorn","text":"Gunicorn is a mature, fully featured server and process manager. Uvicorn includes a Gunicorn worker class allowing you to run ASGI applications, with all of Uvicorn's performance benefits, while also giving you Gunicorn's fully-featured process management. This allows you to increase or decrease the number of worker processes on the fly, restart worker processes gracefully, or perform server upgrades without downtime. For production deployments we recommend using gunicorn with the uvicorn worker class. gunicorn example:app -w 4 -k uvicorn.workers.UvicornWorker For a PyPy compatible configuration use uvicorn.workers.UvicornH11Worker . For more information, see the deployment documentation .","title":"Running with Gunicorn"},{"location":"#application-factories","text":"The --factory flag allows loading the application from a factory function, rather than an application instance directly. The factory will be called with no arguments and should return an ASGI application. example.py : def create_app (): app = ... return app $ uvicorn --factory example:create_app","title":"Application factories"},{"location":"#the-asgi-interface","text":"Uvicorn uses the ASGI specification for interacting with an application. The application should expose an async callable which takes three arguments: scope - A dictionary containing information about the incoming connection. receive - A channel on which to receive incoming messages from the server. send - A channel on which to send outgoing messages to the server. Two common patterns you might use are either function-based applications: async def app ( scope , receive , send ): assert scope [ 'type' ] == 'http' ... Or instance-based applications: class App : async def __call__ ( self , scope , receive , send ): assert scope [ 'type' ] == 'http' ... app = App () It's good practice for applications to raise an exception on scope types that they do not handle. The content of the scope argument, and the messages expected by receive and send depend on the protocol being used. The format for HTTP messages is described in the ASGI HTTP Message format .","title":"The ASGI interface"},{"location":"#http-scope","text":"An incoming HTTP request might have a connection scope like this: { 'type' : 'http.request' , 'scheme' : 'http' , 'root_path' : '' , 'server' : ( '127.0.0.1' , 8000 ), 'http_version' : '1.1' , 'method' : 'GET' , 'path' : '/' , 'headers' : [ [ b 'host' , b '127.0.0.1:8000' ], [ b 'user-agent' , b 'curl/7.51.0' ], [ b 'accept' , b '*/*' ] ] }","title":"HTTP Scope"},{"location":"#http-messages","text":"The instance coroutine communicates back to the server by sending messages to the send coroutine. await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ] }) await send ({ 'type' : 'http.response.body' , 'body' : b 'Hello, world!' , })","title":"HTTP Messages"},{"location":"#requests-responses","text":"Here's an example that displays the method and path used in the incoming request: async def app ( scope , receive , send ): \"\"\" Echo the method and path back in an HTTP response. \"\"\" assert scope [ 'type' ] == 'http' body = f 'Received { scope [ \"method\" ] } request to { scope [ \"path\" ] } ' await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ] }) await send ({ 'type' : 'http.response.body' , 'body' : body . encode ( 'utf-8' ), })","title":"Requests &amp; responses"},{"location":"#reading-the-request-body","text":"You can stream the request body without blocking the asyncio task pool, by fetching messages from the receive coroutine. async def read_body ( receive ): \"\"\" Read and return the entire body from an incoming ASGI message. \"\"\" body = b '' more_body = True while more_body : message = await receive () body += message . get ( 'body' , b '' ) more_body = message . get ( 'more_body' , False ) return body async def app ( scope , receive , send ): \"\"\" Echo the request body back in an HTTP response. \"\"\" body = await read_body ( receive ) await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ] }) await send ({ 'type' : 'http.response.body' , 'body' : body , })","title":"Reading the request body"},{"location":"#streaming-responses","text":"You can stream responses by sending multiple http.response.body messages to the send coroutine. import asyncio async def app ( scope , receive , send ): \"\"\" Send a slowly streaming HTTP response back to the client. \"\"\" await send ({ 'type' : 'http.response.start' , 'status' : 200 , 'headers' : [ [ b 'content-type' , b 'text/plain' ], ] }) for chunk in [ b 'Hello' , b ', ' , b 'world!' ]: await send ({ 'type' : 'http.response.body' , 'body' : chunk , 'more_body' : True }) await asyncio . sleep ( 1 ) await send ({ 'type' : 'http.response.body' , 'body' : b '' , })","title":"Streaming responses"},{"location":"#alternative-asgi-servers","text":"","title":"Alternative ASGI servers"},{"location":"#daphne","text":"The first ASGI server implementation, originally developed to power Django Channels, is the Daphne webserver . It is run widely in production, and supports HTTP/1.1, HTTP/2, and WebSockets. Any of the example applications given here can equally well be run using daphne instead. $ pip install daphne $ daphne app:App","title":"Daphne"},{"location":"#hypercorn","text":"Hypercorn was initially part of the Quart web framework, before being separated out into a standalone ASGI server. Hypercorn supports HTTP/1.1, HTTP/2, and WebSockets. $ pip install hypercorn $ hypercorn app:App","title":"Hypercorn"},{"location":"#asgi-frameworks","text":"You can use Uvicorn, Daphne, or Hypercorn to run any ASGI framework. For small services you can also write ASGI applications directly.","title":"ASGI frameworks"},{"location":"#starlette","text":"Starlette is a lightweight ASGI framework/toolkit. It is ideal for building high performance asyncio services, and supports both HTTP and WebSockets.","title":"Starlette"},{"location":"#django-channels","text":"The ASGI specification was originally designed for use with Django Channels . Channels is a little different to other ASGI frameworks in that it provides an asynchronous frontend onto a threaded-framework backend. It allows Django to support WebSockets, background tasks, and long-running connections, with application code still running in a standard threaded context.","title":"Django Channels"},{"location":"#quart","text":"Quart is a Flask-like ASGI web framework.","title":"Quart"},{"location":"#fastapi","text":"FastAPI is an API framework based on Starlette and Pydantic , heavily inspired by previous server versions of APIStar . You write your API function parameters with Python 3.6+ type declarations and get automatic data conversion, data validation, OpenAPI schemas (with JSON Schemas) and interactive API documentation UIs.","title":"FastAPI"},{"location":"deployment/","text":"Deployment \u00b6 Server deployment is a complex area, that will depend on what kind of service you're deploying Uvicorn onto. As a general rule, you probably want to: Run uvicorn --reload from the command line for local development. Run gunicorn -k uvicorn.workers.UvicornWorker for production. Additionally run behind Nginx for self-hosted deployments. Finally, run everything behind a CDN for caching support, and serious DDOS protection. Running from the command line \u00b6 Typically you'll run uvicorn from the command line. $ uvicorn example:app --reload --port 5000 The ASGI application should be specified in the form path.to.module:instance.path . When running locally, use --reload to turn on auto-reloading. To see the complete set of available options, use uvicorn --help : $ uvicorn --help Usage: uvicorn [OPTIONS] APP Options: --host TEXT Bind socket to this host. [default: 127.0.0.1] --port INTEGER Bind socket to this port. [default: 8000] --uds TEXT Bind to a UNIX domain socket. --fd INTEGER Bind to socket from this file descriptor. --reload Enable auto-reload. --reload-dir TEXT Set reload directories explicitly, instead of using the current working directory. --workers INTEGER Number of worker processes. Defaults to the $WEB_CONCURRENCY environment variable if available. Not valid with --reload. --loop [auto|asyncio|uvloop] Event loop implementation. [default: auto] --http [auto|h11|httptools] HTTP protocol implementation. [default: auto] --ws [auto|none|websockets|wsproto] WebSocket protocol implementation. [default: auto] --lifespan [auto|on|off] Lifespan implementation. [default: auto] --interface [auto|asgi3|asgi2|wsgi] Select ASGI3, ASGI2, or WSGI as the application interface. [default: auto] --env-file PATH Environment configuration file. --log-config PATH Logging configuration file. Supported formats (.ini, .json, .yaml) --log-level [critical|error|warning|info|debug|trace] Log level. [default: info] --access-log / --no-access-log Enable/Disable access log. --use-colors / --no-use-colors Enable/Disable colorized logging. --proxy-headers / --no-proxy-headers Enable/Disable X-Forwarded-Proto, X-Forwarded-For, X-Forwarded-Port to populate remote address info. --forwarded-allow-ips TEXT Comma seperated list of IPs to trust with proxy headers. Defaults to the $FORWARDED_ALLOW_IPS environment variable if available, or '127.0.0.1'. --root-path TEXT Set the ASGI 'root_path' for applications submounted below a given URL path. --limit-concurrency INTEGER Maximum number of concurrent connections or tasks to allow, before issuing HTTP 503 responses. --backlog INTEGER Maximum number of connections to hold in backlog --limit-max-requests INTEGER Maximum number of requests to service before terminating the process. --timeout-keep-alive INTEGER Close Keep-Alive connections if no new data is received within this timeout. [default: 5] --ssl-keyfile TEXT SSL key file --ssl-certfile TEXT SSL certificate file --ssl-keyfile-password TEXT SSL key file password --ssl-version INTEGER SSL version to use (see stdlib ssl module's) [default: 2] --ssl-cert-reqs INTEGER Whether client certificate is required (see stdlib ssl module's) [default: 0] --ssl-ca-certs TEXT CA certificates file --ssl-ciphers TEXT Ciphers to use (see stdlib ssl module's) [default: TLSv1] --header TEXT Specify custom default HTTP response headers as a Name:Value pair --app-dir TEXT Look for APP in the specified directory, by adding this to the PYTHONPATH. Defaults to the current working directory. --help Show this message and exit. See the settings documentation for more details on the supported options for running uvicorn. Running programmatically \u00b6 To run directly from within a Python program, you should use uvicorn.run(app, **config) . For example: example.py : import uvicorn class App : ... app = App () if __name__ == \"__main__\" : uvicorn . run ( \"example:app\" , host = \"127.0.0.1\" , port = 5000 , log_level = \"info\" ) The set of configuration options is the same as for the command line tool. Note that the application instance itself can be passed instead of the app import string. uvicorn . run ( app , host = \"127.0.0.1\" , port = 5000 , log_level = \"info\" ) However, this style only works if you are not using multiprocessing ( workers=NUM ) or reloading ( reload=True ), so we recommend using the import string style. Using a process manager \u00b6 Running Uvicorn using a process manager ensures that you can run multiple processes in a resilient manner, and allows you to perform server upgrades without dropping requests. A process manager will handle the socket setup, start-up multiple server processes, monitor process aliveness, and listen for signals to provide for processes restarts, shutdowns, or dialing up and down the number of running processes. Uvicorn provides a lightweight way to run multiple worker processes, for example --workers 4 , but does not provide any process monitoring. Gunicorn \u00b6 Gunicorn is probably the simplest way to run and manage Uvicorn in a production setting. Uvicorn includes a gunicorn worker class that means you can get set up with very little configuration. The following will start Gunicorn with four worker processes: gunicorn -w 4 -k uvicorn.workers.UvicornWorker The UvicornWorker implementation uses the uvloop and httptools implementations. To run under PyPy you'll want to use pure-python implementation instead. You can do this by using the UvicornH11Worker class. gunicorn -w 4 -k uvicorn.workers.UvicornH11Worker Gunicorn provides a different set of configuration options to Uvicorn, so some options such as --limit-concurrency are not yet supported when running with Gunicorn. Supervisor \u00b6 To use supervisor as a process manager you should either: Hand over the socket to uvicorn using its file descriptor, which supervisor always makes available as 0 , and which must be set in the fcgi-program section. Or use a UNIX domain socket for each uvicorn process. A simple supervisor configuration might look something like this: supervisord.conf : [supervisord] [fcgi-program:uvicorn] socket = tcp://localhost:8000 command = venv/bin/uvicorn --fd 0 example:App numprocs = 4 process_name = uvicorn-%(process_num)d stdout_logfile = /dev/stdout stdout_logfile_maxbytes = 0 Then run with supervisord -n . Circus \u00b6 To use circus as a process manager, you should either: Hand over the socket to uvicorn using its file descriptor, which circus makes available as $(circus.sockets.web) . Or use a UNIX domain socket for each uvicorn process. A simple circus configuration might look something like this: circus.ini : [watcher:web] cmd = venv/bin/uvicorn --fd $(circus.sockets.web) example:App use_sockets = True numprocesses = 4 [socket:web] host = 0.0.0.0 port = 8000 Then run circusd circus.ini . Running behind Nginx \u00b6 Using Nginx as a proxy in front of your Uvicorn processes may not be neccessary, but is recommended for additional resiliance. Nginx can deal with serving your static media and buffering slow requests, leaving your application servers free from load as much as possible. In managed environments such as Heroku , you wont typically need to configure Nginx, as your server processes will already be running behind load balancing proxies. The recommended configuration for proxying from Nginx is to use a UNIX domain socket between Nginx and whatever the process manager that is being used to run Uvicorn. Note that when doing this you will need run Uvicorn with --forwarded-allow-ips='*' to ensure that the domain socket is trusted as a source from which to proxy headers. When fronting the application with a proxy server you want to make sure that the proxy sets headers to ensure that application can properly determine the client address of the incoming connection, and if the connection was over http or https . You should ensure that the X-Forwarded-For and X-Forwarded-Proto headers are set by the proxy, and that Uvicorn is run using the --proxy-headers setting. This ensure that the ASGI scope includes correct client and scheme information. Here's how a simple Nginx configuration might look. This example includes setting proxy headers, and using a UNIX domain socket to communicate with the application server. http { server { listen 80; client_max_body_size 4G; server_name example.com; location / { proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_redirect off; proxy_buffering off; proxy_pass http://uvicorn; } location /static { # path for static files root /path/to/app/static; } } upstream uvicorn { server unix:/tmp/uvicorn.sock; } } Uvicorn's --proxy-headers behavior may not be sufficient for more complex proxy configurations that use different combinations of headers, or where the application is running behind more than one intermediary proxying service. In those cases you might want to use an ASGI middleware to set the client and scheme dependant on the request headers. Running behind a CDN \u00b6 Running behind a content delivery network, such as Cloudflare or Cloud Front, provides a serious layer of protection against DDOS attacks. Your sevice will be running behind huge clusters of proxies and load balancers that are designed for handling huge amounts of traffic, and have capabilities for detecting and closing off connections from DDOS attacks. Proper usage of cache control headers can mean that a CDN is able to serve large amounts of data without always having to forward the request on to your server. Content Delivery Networks can also be a low-effort way to provide HTTPS termination. Running with HTTPS \u00b6 To run uvicorn with https, a certificate and a private key are required. The recommended way to get them is using Let's Encrypt . For local development with https, it's possible to use mkcert to generate a valid certificate and private key. $ uvicorn example:app --port 5000 --ssl-keyfile = ./key.pem --ssl-certfile = ./cert.pem Running gunicorn worker \u00b6 It also possible to use certificates with uvicorn's worker for gunicorn $ gunicorn --keyfile = ./key.pem --certfile = ./cert.pem -k uvicorn.workers.UvicornWorker example:app","title":"Deployment"},{"location":"deployment/#deployment","text":"Server deployment is a complex area, that will depend on what kind of service you're deploying Uvicorn onto. As a general rule, you probably want to: Run uvicorn --reload from the command line for local development. Run gunicorn -k uvicorn.workers.UvicornWorker for production. Additionally run behind Nginx for self-hosted deployments. Finally, run everything behind a CDN for caching support, and serious DDOS protection.","title":"Deployment"},{"location":"deployment/#running-from-the-command-line","text":"Typically you'll run uvicorn from the command line. $ uvicorn example:app --reload --port 5000 The ASGI application should be specified in the form path.to.module:instance.path . When running locally, use --reload to turn on auto-reloading. To see the complete set of available options, use uvicorn --help : $ uvicorn --help Usage: uvicorn [OPTIONS] APP Options: --host TEXT Bind socket to this host. [default: 127.0.0.1] --port INTEGER Bind socket to this port. [default: 8000] --uds TEXT Bind to a UNIX domain socket. --fd INTEGER Bind to socket from this file descriptor. --reload Enable auto-reload. --reload-dir TEXT Set reload directories explicitly, instead of using the current working directory. --workers INTEGER Number of worker processes. Defaults to the $WEB_CONCURRENCY environment variable if available. Not valid with --reload. --loop [auto|asyncio|uvloop] Event loop implementation. [default: auto] --http [auto|h11|httptools] HTTP protocol implementation. [default: auto] --ws [auto|none|websockets|wsproto] WebSocket protocol implementation. [default: auto] --lifespan [auto|on|off] Lifespan implementation. [default: auto] --interface [auto|asgi3|asgi2|wsgi] Select ASGI3, ASGI2, or WSGI as the application interface. [default: auto] --env-file PATH Environment configuration file. --log-config PATH Logging configuration file. Supported formats (.ini, .json, .yaml) --log-level [critical|error|warning|info|debug|trace] Log level. [default: info] --access-log / --no-access-log Enable/Disable access log. --use-colors / --no-use-colors Enable/Disable colorized logging. --proxy-headers / --no-proxy-headers Enable/Disable X-Forwarded-Proto, X-Forwarded-For, X-Forwarded-Port to populate remote address info. --forwarded-allow-ips TEXT Comma seperated list of IPs to trust with proxy headers. Defaults to the $FORWARDED_ALLOW_IPS environment variable if available, or '127.0.0.1'. --root-path TEXT Set the ASGI 'root_path' for applications submounted below a given URL path. --limit-concurrency INTEGER Maximum number of concurrent connections or tasks to allow, before issuing HTTP 503 responses. --backlog INTEGER Maximum number of connections to hold in backlog --limit-max-requests INTEGER Maximum number of requests to service before terminating the process. --timeout-keep-alive INTEGER Close Keep-Alive connections if no new data is received within this timeout. [default: 5] --ssl-keyfile TEXT SSL key file --ssl-certfile TEXT SSL certificate file --ssl-keyfile-password TEXT SSL key file password --ssl-version INTEGER SSL version to use (see stdlib ssl module's) [default: 2] --ssl-cert-reqs INTEGER Whether client certificate is required (see stdlib ssl module's) [default: 0] --ssl-ca-certs TEXT CA certificates file --ssl-ciphers TEXT Ciphers to use (see stdlib ssl module's) [default: TLSv1] --header TEXT Specify custom default HTTP response headers as a Name:Value pair --app-dir TEXT Look for APP in the specified directory, by adding this to the PYTHONPATH. Defaults to the current working directory. --help Show this message and exit. See the settings documentation for more details on the supported options for running uvicorn.","title":"Running from the command line"},{"location":"deployment/#running-programmatically","text":"To run directly from within a Python program, you should use uvicorn.run(app, **config) . For example: example.py : import uvicorn class App : ... app = App () if __name__ == \"__main__\" : uvicorn . run ( \"example:app\" , host = \"127.0.0.1\" , port = 5000 , log_level = \"info\" ) The set of configuration options is the same as for the command line tool. Note that the application instance itself can be passed instead of the app import string. uvicorn . run ( app , host = \"127.0.0.1\" , port = 5000 , log_level = \"info\" ) However, this style only works if you are not using multiprocessing ( workers=NUM ) or reloading ( reload=True ), so we recommend using the import string style.","title":"Running programmatically"},{"location":"deployment/#using-a-process-manager","text":"Running Uvicorn using a process manager ensures that you can run multiple processes in a resilient manner, and allows you to perform server upgrades without dropping requests. A process manager will handle the socket setup, start-up multiple server processes, monitor process aliveness, and listen for signals to provide for processes restarts, shutdowns, or dialing up and down the number of running processes. Uvicorn provides a lightweight way to run multiple worker processes, for example --workers 4 , but does not provide any process monitoring.","title":"Using a process manager"},{"location":"deployment/#gunicorn","text":"Gunicorn is probably the simplest way to run and manage Uvicorn in a production setting. Uvicorn includes a gunicorn worker class that means you can get set up with very little configuration. The following will start Gunicorn with four worker processes: gunicorn -w 4 -k uvicorn.workers.UvicornWorker The UvicornWorker implementation uses the uvloop and httptools implementations. To run under PyPy you'll want to use pure-python implementation instead. You can do this by using the UvicornH11Worker class. gunicorn -w 4 -k uvicorn.workers.UvicornH11Worker Gunicorn provides a different set of configuration options to Uvicorn, so some options such as --limit-concurrency are not yet supported when running with Gunicorn.","title":"Gunicorn"},{"location":"deployment/#supervisor","text":"To use supervisor as a process manager you should either: Hand over the socket to uvicorn using its file descriptor, which supervisor always makes available as 0 , and which must be set in the fcgi-program section. Or use a UNIX domain socket for each uvicorn process. A simple supervisor configuration might look something like this: supervisord.conf : [supervisord] [fcgi-program:uvicorn] socket = tcp://localhost:8000 command = venv/bin/uvicorn --fd 0 example:App numprocs = 4 process_name = uvicorn-%(process_num)d stdout_logfile = /dev/stdout stdout_logfile_maxbytes = 0 Then run with supervisord -n .","title":"Supervisor"},{"location":"deployment/#circus","text":"To use circus as a process manager, you should either: Hand over the socket to uvicorn using its file descriptor, which circus makes available as $(circus.sockets.web) . Or use a UNIX domain socket for each uvicorn process. A simple circus configuration might look something like this: circus.ini : [watcher:web] cmd = venv/bin/uvicorn --fd $(circus.sockets.web) example:App use_sockets = True numprocesses = 4 [socket:web] host = 0.0.0.0 port = 8000 Then run circusd circus.ini .","title":"Circus"},{"location":"deployment/#running-behind-nginx","text":"Using Nginx as a proxy in front of your Uvicorn processes may not be neccessary, but is recommended for additional resiliance. Nginx can deal with serving your static media and buffering slow requests, leaving your application servers free from load as much as possible. In managed environments such as Heroku , you wont typically need to configure Nginx, as your server processes will already be running behind load balancing proxies. The recommended configuration for proxying from Nginx is to use a UNIX domain socket between Nginx and whatever the process manager that is being used to run Uvicorn. Note that when doing this you will need run Uvicorn with --forwarded-allow-ips='*' to ensure that the domain socket is trusted as a source from which to proxy headers. When fronting the application with a proxy server you want to make sure that the proxy sets headers to ensure that application can properly determine the client address of the incoming connection, and if the connection was over http or https . You should ensure that the X-Forwarded-For and X-Forwarded-Proto headers are set by the proxy, and that Uvicorn is run using the --proxy-headers setting. This ensure that the ASGI scope includes correct client and scheme information. Here's how a simple Nginx configuration might look. This example includes setting proxy headers, and using a UNIX domain socket to communicate with the application server. http { server { listen 80; client_max_body_size 4G; server_name example.com; location / { proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_redirect off; proxy_buffering off; proxy_pass http://uvicorn; } location /static { # path for static files root /path/to/app/static; } } upstream uvicorn { server unix:/tmp/uvicorn.sock; } } Uvicorn's --proxy-headers behavior may not be sufficient for more complex proxy configurations that use different combinations of headers, or where the application is running behind more than one intermediary proxying service. In those cases you might want to use an ASGI middleware to set the client and scheme dependant on the request headers.","title":"Running behind Nginx"},{"location":"deployment/#running-behind-a-cdn","text":"Running behind a content delivery network, such as Cloudflare or Cloud Front, provides a serious layer of protection against DDOS attacks. Your sevice will be running behind huge clusters of proxies and load balancers that are designed for handling huge amounts of traffic, and have capabilities for detecting and closing off connections from DDOS attacks. Proper usage of cache control headers can mean that a CDN is able to serve large amounts of data without always having to forward the request on to your server. Content Delivery Networks can also be a low-effort way to provide HTTPS termination.","title":"Running behind a CDN"},{"location":"deployment/#running-with-https","text":"To run uvicorn with https, a certificate and a private key are required. The recommended way to get them is using Let's Encrypt . For local development with https, it's possible to use mkcert to generate a valid certificate and private key. $ uvicorn example:app --port 5000 --ssl-keyfile = ./key.pem --ssl-certfile = ./cert.pem","title":"Running with HTTPS"},{"location":"deployment/#running-gunicorn-worker","text":"It also possible to use certificates with uvicorn's worker for gunicorn $ gunicorn --keyfile = ./key.pem --certfile = ./cert.pem -k uvicorn.workers.UvicornWorker example:app","title":"Running gunicorn worker"},{"location":"server-behavior/","text":"Server Behavior \u00b6 Uvicorn is designed with particular attention to connection and resource management, in order to provide a robust server implementation. It aims to ensure graceful behavior to either server or client errors, and resilience to poor client behavior or denial of service attacks. HTTP Headers \u00b6 The Server and Date headers are added to all outgoing requests. If a Connection: Close header is included then Uvicorn will close the connection after the response. Otherwise connections will stay open, pending the keep-alive timeout. If a Content-Length header is included then Uvicorn will ensure that the content length of the response body matches the value in the header, and raise an error otherwise. If no Content-Length header is included then Uvicorn will use chunked encoding for the response body, and will set a Transfer-Encoding header if required. If a Transfer-Encoding header is included then any Content-Length header will be ignored. HTTP headers are mandated to be case-insensitive. Uvicorn will always send response headers strictly in lowercase. Flow Control \u00b6 Proper flow control ensures that large amounts of data does not become buffered on the transport when either side of a connection is sending data faster than its counterpart is able to handle. Write flow control \u00b6 If the write buffer passes a high water mark, then Uvicorn ensures the ASGI send messages will only return once the write buffer has been drained below the low water mark. Read flow control \u00b6 Uvicorn will pause reading from a transport once the buffered request body hits a high water mark, and will only resume once receive has been called, or once the response has been sent. Request and Response bodies \u00b6 Response completion \u00b6 Once a response has been sent, Uvicorn will no longer buffer any remaining request body. Any later calls to receive will return an http.disconnect message. Together with the read flow control, this behavior ensures that responses that return without reading the request body will not stream any substantial amounts of data into memory. Expect: 100-Continue \u00b6 The Expect: 100-Continue header may be sent by clients to require a confirmation from the server before uploading the request body. This can be used to ensure that large request bodies are only sent once the client has confirmation that the server is willing to accept the request. Uvicorn ensures that any required 100 Continue confirmations are only sent if the ASGI application calls receive to read the request body. Note that that proxy configurations may not necessarily forward on Expect: 100-Continue headers. In particular Nginx defaults to buffering request bodies, and automatically sends 100 Continues rather than passing the header on to the upstream server. HEAD requests \u00b6 Uvicorn will strip any response body from HTTP requests with the HEAD method. Applications should generally treat HEAD requests in the same manner as GET requests, in order to ensure that identical headers are sent in both cases, and that any ASGI middleware that modifies the headers will operate identically in either case. One exception to this might be if your application serves large file downloads, in which case you might wish to only generate the response headers. Timeouts \u00b6 Uvicorn provides the following timeouts: Keep-Alive. Defaults to 5 seconds. Between requests, connections must receive new data within this period or be disconnected. Resource Limits \u00b6 Uvicorn provides the following resource limiting: Concurrency. Defaults to None . If set, this provides a maximum number of concurrent tasks or open connections that should be allowed. Any new requests or connections that occur once this limit has been reached will result in a \"503 Service Unavailable\" response. Setting this value to a limit that you know your servers are able to support will help ensure reliable resource usage, even against significantly over-resourced servers. Max requests. Defaults to None . If set, this provides a maximum number of HTTP requests that will be serviced before terminating a process. Together with a process manager this can be used to prevent memory leaks from impacting long running processes. Server Errors \u00b6 Server errors will be logged at the error log level. All logging defaults to being written to stdout . Exceptions \u00b6 If an exception is raised by an ASGI application, and a response has not yet been sent on the connection, then a 500 Server Error HTTP response will be sent. Invalid responses \u00b6 Uvicorn will ensure that ASGI applications send the correct sequence of messages, and will raise errors otherwise. This includes checking for no response sent, partial response sent, or invalid message sequences being sent. Graceful Process Shutdown \u00b6 Graceful process shutdowns are particularly important during a restart period. During this period you want to: Start a number of new server processes to handle incoming requests, listening on the existing socket. Stop the previous server processes from listening on the existing socket. Close any connections that are not currently waiting on an HTTP response, and wait for any other connections to finalize their HTTP responses. Wait for any background tasks to run to completion, such as occurs when the ASGI application has sent the HTTP response, but the asyncio task has not yet run to completion. Uvicorn handles process shutdown gracefully, ensuring that connections are properly finalized, and all tasks have run to completion. During a shutdown period Uvicorn will ensure that responses and tasks must still complete within the configured timeout periods. HTTP Pipelining \u00b6 HTTP/1.1 provides support for sending multiple requests on a single connection, before having received each corresponding response. Servers are required to support HTTP pipelining, but it is now generally accepted to lead to implementation issues. It is not enabled on browsers, and may not necessarily be enabled on any proxies that the HTTP request passes through. Uvicorn supports pipelining pragmatically. It will queue up any pipelined HTTP requests, and pause reading from the underlying transport. It will not start processing pipelined requests until each response has been dealt with in turn.","title":"Server Behavior"},{"location":"server-behavior/#server-behavior","text":"Uvicorn is designed with particular attention to connection and resource management, in order to provide a robust server implementation. It aims to ensure graceful behavior to either server or client errors, and resilience to poor client behavior or denial of service attacks.","title":"Server Behavior"},{"location":"server-behavior/#http-headers","text":"The Server and Date headers are added to all outgoing requests. If a Connection: Close header is included then Uvicorn will close the connection after the response. Otherwise connections will stay open, pending the keep-alive timeout. If a Content-Length header is included then Uvicorn will ensure that the content length of the response body matches the value in the header, and raise an error otherwise. If no Content-Length header is included then Uvicorn will use chunked encoding for the response body, and will set a Transfer-Encoding header if required. If a Transfer-Encoding header is included then any Content-Length header will be ignored. HTTP headers are mandated to be case-insensitive. Uvicorn will always send response headers strictly in lowercase.","title":"HTTP Headers"},{"location":"server-behavior/#flow-control","text":"Proper flow control ensures that large amounts of data does not become buffered on the transport when either side of a connection is sending data faster than its counterpart is able to handle.","title":"Flow Control"},{"location":"server-behavior/#write-flow-control","text":"If the write buffer passes a high water mark, then Uvicorn ensures the ASGI send messages will only return once the write buffer has been drained below the low water mark.","title":"Write flow control"},{"location":"server-behavior/#read-flow-control","text":"Uvicorn will pause reading from a transport once the buffered request body hits a high water mark, and will only resume once receive has been called, or once the response has been sent.","title":"Read flow control"},{"location":"server-behavior/#request-and-response-bodies","text":"","title":"Request and Response bodies"},{"location":"server-behavior/#response-completion","text":"Once a response has been sent, Uvicorn will no longer buffer any remaining request body. Any later calls to receive will return an http.disconnect message. Together with the read flow control, this behavior ensures that responses that return without reading the request body will not stream any substantial amounts of data into memory.","title":"Response completion"},{"location":"server-behavior/#expect-100-continue","text":"The Expect: 100-Continue header may be sent by clients to require a confirmation from the server before uploading the request body. This can be used to ensure that large request bodies are only sent once the client has confirmation that the server is willing to accept the request. Uvicorn ensures that any required 100 Continue confirmations are only sent if the ASGI application calls receive to read the request body. Note that that proxy configurations may not necessarily forward on Expect: 100-Continue headers. In particular Nginx defaults to buffering request bodies, and automatically sends 100 Continues rather than passing the header on to the upstream server.","title":"Expect: 100-Continue"},{"location":"server-behavior/#head-requests","text":"Uvicorn will strip any response body from HTTP requests with the HEAD method. Applications should generally treat HEAD requests in the same manner as GET requests, in order to ensure that identical headers are sent in both cases, and that any ASGI middleware that modifies the headers will operate identically in either case. One exception to this might be if your application serves large file downloads, in which case you might wish to only generate the response headers.","title":"HEAD requests"},{"location":"server-behavior/#timeouts","text":"Uvicorn provides the following timeouts: Keep-Alive. Defaults to 5 seconds. Between requests, connections must receive new data within this period or be disconnected.","title":"Timeouts"},{"location":"server-behavior/#resource-limits","text":"Uvicorn provides the following resource limiting: Concurrency. Defaults to None . If set, this provides a maximum number of concurrent tasks or open connections that should be allowed. Any new requests or connections that occur once this limit has been reached will result in a \"503 Service Unavailable\" response. Setting this value to a limit that you know your servers are able to support will help ensure reliable resource usage, even against significantly over-resourced servers. Max requests. Defaults to None . If set, this provides a maximum number of HTTP requests that will be serviced before terminating a process. Together with a process manager this can be used to prevent memory leaks from impacting long running processes.","title":"Resource Limits"},{"location":"server-behavior/#server-errors","text":"Server errors will be logged at the error log level. All logging defaults to being written to stdout .","title":"Server Errors"},{"location":"server-behavior/#exceptions","text":"If an exception is raised by an ASGI application, and a response has not yet been sent on the connection, then a 500 Server Error HTTP response will be sent.","title":"Exceptions"},{"location":"server-behavior/#invalid-responses","text":"Uvicorn will ensure that ASGI applications send the correct sequence of messages, and will raise errors otherwise. This includes checking for no response sent, partial response sent, or invalid message sequences being sent.","title":"Invalid responses"},{"location":"server-behavior/#graceful-process-shutdown","text":"Graceful process shutdowns are particularly important during a restart period. During this period you want to: Start a number of new server processes to handle incoming requests, listening on the existing socket. Stop the previous server processes from listening on the existing socket. Close any connections that are not currently waiting on an HTTP response, and wait for any other connections to finalize their HTTP responses. Wait for any background tasks to run to completion, such as occurs when the ASGI application has sent the HTTP response, but the asyncio task has not yet run to completion. Uvicorn handles process shutdown gracefully, ensuring that connections are properly finalized, and all tasks have run to completion. During a shutdown period Uvicorn will ensure that responses and tasks must still complete within the configured timeout periods.","title":"Graceful Process Shutdown"},{"location":"server-behavior/#http-pipelining","text":"HTTP/1.1 provides support for sending multiple requests on a single connection, before having received each corresponding response. Servers are required to support HTTP pipelining, but it is now generally accepted to lead to implementation issues. It is not enabled on browsers, and may not necessarily be enabled on any proxies that the HTTP request passes through. Uvicorn supports pipelining pragmatically. It will queue up any pipelined HTTP requests, and pause reading from the underlying transport. It will not start processing pipelined requests until each response has been dealt with in turn.","title":"HTTP Pipelining"},{"location":"settings/","text":"Settings \u00b6 Use the following options to configure Uvicorn, when running from the command line. If you're running using programmatically, using uvicorn.run(...) , then use equivalent keyword arguments, eg. uvicorn.run(\"example:app\", port=5000, reload=True, access_log=False) . Application \u00b6 APP - The ASGI application to run, in the format \"<module>:<attribute>\" . --factory - Treat APP as an application factory, i.e. a () -> <ASGI app> callable. Socket Binding \u00b6 --host <str> - Bind socket to this host. Use --host 0.0.0.0 to make the application available on your local network. IPv6 addresses are supported, for example: --host '::' . Default: '127.0.0.1' . --port <int> - Bind to a socket with this port. Default: 8000 . --uds <str> - Bind to a UNIX domain socket. Useful if you want to run Uvicorn behind a reverse proxy. --fd <int> - Bind to socket from this file descriptor. Useful if you want to run Uvicorn within a process manager. Development \u00b6 --reload - Enable auto-reload. --reload-dir <path> - Specify which directories to watch for python file changes. May be used multiple times. If unused, then by default all directories in current directory will be watched. By default Uvicorn uses simple changes detection strategy that compares python files modification times few times a second. If this approach doesn't work for your project (eg. because of its complexity), you can install Uvicorn with optional watchgod dependency to use filesystem events instead: $ pip install uvicorn[watchgodreload] Production \u00b6 --workers <int> - Use multiple worker processes. Defaults to the value of the $WEB_CONCURRENCY environment variable. Logging \u00b6 --log-config <path> - Logging configuration file. Options: dictConfig() formats: .json, .yaml . Any other format will be processed with fileConfig() . Set the formatters.default.use_colors and formatters.access.use_colors values to override the auto-detected behavior. If you wish to use a YAML file for your logging config, you will need to include PyYAML as a dependency for your project or install uvicorn with the [standard] optional extras. --log-level <str> - Set the log level. Options: 'critical', 'error', 'warning', 'info', 'debug', 'trace'. Default: 'info' . --no-access-log - Disable access log only, without changing log level. --use-colors / --no-use-colors - Enable / disable colorized formatting of the log records, in case this is not set it will be auto-detected. This option is ignored if the --log-config CLI option is used. Implementation \u00b6 --loop <str> - Set the event loop implementation. The uvloop implementation provides greater performance, but is not compatible with Windows or PyPy. Options: 'auto', 'asyncio', 'uvloop'. Default: 'auto' . --http <str> - Set the HTTP protocol implementation. The httptools implementation provides greater performance, but it not compatible with PyPy, and requires compilation on Windows. Options: 'auto', 'h11', 'httptools'. Default: 'auto' . --ws <str> - Set the WebSockets protocol implementation. Either of the websockets and wsproto packages are supported. Use 'none' to deny all websocket requests. Options: 'auto', 'none', 'websockets', 'wsproto'. Default: 'auto' . --lifespan <str> - Set the Lifespan protocol implementation. Options: 'auto', 'on', 'off'. Default: 'auto' . Application Interface \u00b6 --interface - Select ASGI3, ASGI2, or WSGI as the application interface. Note that WSGI mode always disables WebSocket support, as it is not supported by the WSGI interface. Options: 'auto', 'asgi3', 'asgi2', 'wsgi'. Default: 'auto' . HTTP \u00b6 --root-path <str> - Set the ASGI root_path for applications submounted below a given URL path. --proxy-headers / --no-proxy-headers - Enable/Disable X-Forwarded-Proto, X-Forwarded-For, X-Forwarded-Port to populate remote address info. Defaults to enabled, but is restricted to only trusting connecting IPs in the forwarded-allow-ips configuration. --forwarded-allow-ips Comma separated list of IPs to trust with proxy headers. Defaults to the $FORWARDED_ALLOW_IPS environment variable if available, or '127.0.0.1'. A wildcard '*' means always trust. HTTPS \u00b6 --ssl-keyfile <path> - SSL key file --ssl-keyfile-password <str> - Password to decrypt the ssl key --ssl-certfile <path> - SSL certificate file --ssl-version <int> - SSL version to use (see stdlib ssl module's) --ssl-cert-reqs <int> - Whether client certificate is required (see stdlib ssl module's) --ssl-ca-certs <str> - CA certificates file --ssl-ciphers <str> - Ciphers to use (see stdlib ssl module's) Resource Limits \u00b6 --limit-concurrency <int> - Maximum number of concurrent connections or tasks to allow, before issuing HTTP 503 responses. Useful for ensuring known memory usage patterns even under over-resourced loads. --limit-max-requests <int> - Maximum number of requests to service before terminating the process. Useful when running together with a process manager, for preventing memory leaks from impacting long-running processes. --backlog <int> - Maximum number of connections to hold in backlog. Relevant for heavy incoming traffic. Default: 2048 Timeouts \u00b6 --timeout-keep-alive <int> - Close Keep-Alive connections if no new data is received within this timeout. Default: 5 .","title":"Settings"},{"location":"settings/#settings","text":"Use the following options to configure Uvicorn, when running from the command line. If you're running using programmatically, using uvicorn.run(...) , then use equivalent keyword arguments, eg. uvicorn.run(\"example:app\", port=5000, reload=True, access_log=False) .","title":"Settings"},{"location":"settings/#application","text":"APP - The ASGI application to run, in the format \"<module>:<attribute>\" . --factory - Treat APP as an application factory, i.e. a () -> <ASGI app> callable.","title":"Application"},{"location":"settings/#socket-binding","text":"--host <str> - Bind socket to this host. Use --host 0.0.0.0 to make the application available on your local network. IPv6 addresses are supported, for example: --host '::' . Default: '127.0.0.1' . --port <int> - Bind to a socket with this port. Default: 8000 . --uds <str> - Bind to a UNIX domain socket. Useful if you want to run Uvicorn behind a reverse proxy. --fd <int> - Bind to socket from this file descriptor. Useful if you want to run Uvicorn within a process manager.","title":"Socket Binding"},{"location":"settings/#development","text":"--reload - Enable auto-reload. --reload-dir <path> - Specify which directories to watch for python file changes. May be used multiple times. If unused, then by default all directories in current directory will be watched. By default Uvicorn uses simple changes detection strategy that compares python files modification times few times a second. If this approach doesn't work for your project (eg. because of its complexity), you can install Uvicorn with optional watchgod dependency to use filesystem events instead: $ pip install uvicorn[watchgodreload]","title":"Development"},{"location":"settings/#production","text":"--workers <int> - Use multiple worker processes. Defaults to the value of the $WEB_CONCURRENCY environment variable.","title":"Production"},{"location":"settings/#logging","text":"--log-config <path> - Logging configuration file. Options: dictConfig() formats: .json, .yaml . Any other format will be processed with fileConfig() . Set the formatters.default.use_colors and formatters.access.use_colors values to override the auto-detected behavior. If you wish to use a YAML file for your logging config, you will need to include PyYAML as a dependency for your project or install uvicorn with the [standard] optional extras. --log-level <str> - Set the log level. Options: 'critical', 'error', 'warning', 'info', 'debug', 'trace'. Default: 'info' . --no-access-log - Disable access log only, without changing log level. --use-colors / --no-use-colors - Enable / disable colorized formatting of the log records, in case this is not set it will be auto-detected. This option is ignored if the --log-config CLI option is used.","title":"Logging"},{"location":"settings/#implementation","text":"--loop <str> - Set the event loop implementation. The uvloop implementation provides greater performance, but is not compatible with Windows or PyPy. Options: 'auto', 'asyncio', 'uvloop'. Default: 'auto' . --http <str> - Set the HTTP protocol implementation. The httptools implementation provides greater performance, but it not compatible with PyPy, and requires compilation on Windows. Options: 'auto', 'h11', 'httptools'. Default: 'auto' . --ws <str> - Set the WebSockets protocol implementation. Either of the websockets and wsproto packages are supported. Use 'none' to deny all websocket requests. Options: 'auto', 'none', 'websockets', 'wsproto'. Default: 'auto' . --lifespan <str> - Set the Lifespan protocol implementation. Options: 'auto', 'on', 'off'. Default: 'auto' .","title":"Implementation"},{"location":"settings/#application-interface","text":"--interface - Select ASGI3, ASGI2, or WSGI as the application interface. Note that WSGI mode always disables WebSocket support, as it is not supported by the WSGI interface. Options: 'auto', 'asgi3', 'asgi2', 'wsgi'. Default: 'auto' .","title":"Application Interface"},{"location":"settings/#http","text":"--root-path <str> - Set the ASGI root_path for applications submounted below a given URL path. --proxy-headers / --no-proxy-headers - Enable/Disable X-Forwarded-Proto, X-Forwarded-For, X-Forwarded-Port to populate remote address info. Defaults to enabled, but is restricted to only trusting connecting IPs in the forwarded-allow-ips configuration. --forwarded-allow-ips Comma separated list of IPs to trust with proxy headers. Defaults to the $FORWARDED_ALLOW_IPS environment variable if available, or '127.0.0.1'. A wildcard '*' means always trust.","title":"HTTP"},{"location":"settings/#https","text":"--ssl-keyfile <path> - SSL key file --ssl-keyfile-password <str> - Password to decrypt the ssl key --ssl-certfile <path> - SSL certificate file --ssl-version <int> - SSL version to use (see stdlib ssl module's) --ssl-cert-reqs <int> - Whether client certificate is required (see stdlib ssl module's) --ssl-ca-certs <str> - CA certificates file --ssl-ciphers <str> - Ciphers to use (see stdlib ssl module's)","title":"HTTPS"},{"location":"settings/#resource-limits","text":"--limit-concurrency <int> - Maximum number of concurrent connections or tasks to allow, before issuing HTTP 503 responses. Useful for ensuring known memory usage patterns even under over-resourced loads. --limit-max-requests <int> - Maximum number of requests to service before terminating the process. Useful when running together with a process manager, for preventing memory leaks from impacting long-running processes. --backlog <int> - Maximum number of connections to hold in backlog. Relevant for heavy incoming traffic. Default: 2048","title":"Resource Limits"},{"location":"settings/#timeouts","text":"--timeout-keep-alive <int> - Close Keep-Alive connections if no new data is received within this timeout. Default: 5 .","title":"Timeouts"}]}